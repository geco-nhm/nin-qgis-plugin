#Store empty columns
empty_columns <- which(colSums(mean_confusion_matrix, na.rm = TRUE) == 0)
as.matrix(mean_confusion_matrix)
diag(as.matrix(mean_confusion_matrix))
sum(mean_confusion_matrix, na.rm = TRUE)
sum(diag(as.matrix(mean_confusion_matrix)), na.rm = TRUE)/sum(mean_confusion_matrix, na.rm = TRUE)
#Aggregate the confusion matrices with the mean
sum_confusion_matrix <- apply(confusion_array, c(1,2), sum, na.rm = TRUE)
sum_confusion_matrix
#Aggregate the confusion matrices with the mean
sum_confusion_matrix <- apply(confusion_array, c(1,2), sum, na.rm = TRUE)
#Convert to data frame and convert to columns and rows
sum_confusion_matrix <- convert.names(sum_confusion_matrix, names_classes)
View(sum_confusion_matrix)
confusion_list <- municipality_matrix_list
n_classes <- nrow(municipality_matrix_list[[1]])
names_classes <- colnames(municipality_matrix_list[[1]])
progress = TRUE
filename <- "aggregated_confusion"
#Function to aggregate confusion matrices
confusion.matrix <- function(data, n_class, progress = TRUE, filename) {
#Create matrix for storing confusion matrices
confusion_matrix <- matrix()
#Create array for storing confusion matrices
confusion_array <- array(matrix(0,n_classes,n_classes), dim = c(n_classes,n_classes,length(confusion_list)))
#Aggregate confusion matrices within the hierarchical level
for (k in 1:length(confusion_list)) {
#Create template with all classes for storing confusion matrix results
confusion_template <- matrix(0,n_classes,n_classes)
#Store confusion matrix k
confusion_matrix <- confusion_list[[k]]
#Store confusion matrix from one model in the template
for (i in 1:ncol(confusion_matrix)) {
for (j in 1:nrow(confusion_matrix)) {
#Add values from confusion matrix k to the template
confusion_template[j,i] <- confusion_template[j,i] + confusion_matrix[j,i]
}
}
#Add results from confusion matrix k to the array
confusion_array[,,k] <- confusion_template
#Print progress
if (progress == T) {
print(k/length(confusion_list))
}
}
#Store the number of test points for each class
test_numbers <- colSums(apply(confusion_array, c(1,2), sum, na.rm = TRUE))
#Convert to km2
test_numbers <- round(test_numbers / 1000000, 0)
#Store the total number of test points
total_number <- sum(test_numbers, na.rm = TRUE)
#Aggregate the confusion matrices with the mean
mean_confusion_matrix <- apply(confusion_array, c(1,2), mean, na.rm = TRUE)
#Convert to data frame and convert to columns and rows
mean_confusion_matrix <- convert.names(mean_confusion_matrix, names_classes)
#Aggregate the confusion matrices with the standard deviation
sd_confusion_matrix <- apply(confusion_array, c(1,2), sd, na.rm = TRUE)
#Convert to data frame and convert to columns and rows
sd_confusion_matrix <- convert.names(sd_confusion_matrix, names_classes)
#Aggregate the confusion matrices with the mean
sum_confusion_matrix <- apply(confusion_array, c(1,2), sum, na.rm = TRUE)
#Convert to data frame and convert to columns and rows
sum_confusion_matrix <- convert.names(sum_confusion_matrix, names_classes)
#Identify rows that will be removed
#nonzero <- sort(unique(c(which(rowSums(mean_confusion_matrix, na.rm = TRUE) != 0), which(colSums(mean_confusion_matrix, na.rm = TRUE) != 0))), decreasing = F)
#Specify number of test points for all classes in the matrix
#test_numbers <- test_numbers[nonzero]
#Remove zero columns
#mean_confusion_matrix <- mean_confusion_matrix[nonzero,nonzero]
#sd_confusion_matrix <- sd_confusion_matrix[nonzero,nonzero]
#Assign the number of tested points to the name for each class
colnames(mean_confusion_matrix) <- paste(colnames(mean_confusion_matrix)," (",test_numbers,")", sep = "")
#Calculate user's accuracy
users_accuracy <- diag(as.matrix(sum_confusion_matrix))/rowSums(sum_confusion_matrix, na.rm = TRUE)
users_accuracy[is.nan(users_accuracy)] <- NA
#Store empty rows
empty_rows <- which(rowSums(mean_confusion_matrix, na.rm = TRUE) == 0)
#Calcuate producer's accuracy
producers_accuracy <- diag(as.matrix(sum_confusion_matrix))/colSums(sum_confusion_matrix, na.rm = TRUE)
producers_accuracy[is.nan(producers_accuracy)] <- NA
#Store empty columns
empty_columns <- which(colSums(mean_confusion_matrix, na.rm = TRUE) == 0)
#Calculate overall Accuracy
overall_accuracy <- sum(diag(as.matrix(sum_confusion_matrix)), na.rm = TRUE)/sum(sum_confusion_matrix, na.rm = TRUE)
#Create a matrix to store concatenated matrices
concatenated_matrix <- matrix("", nrow = nrow(mean_confusion_matrix), ncol = ncol(mean_confusion_matrix))
#Convert from numeric to character and concatenate matrices cell-wise
for (i in 1:nrow(mean_confusion_matrix)) {
for (j in 1:ncol(mean_confusion_matrix)) {
concatenated_matrix[i,j] <- paste(as.character(mean_confusion_matrix[i,j]),"\u00B1", as.character(sd_confusion_matrix[i,j]), sep = "")
}
}
#Convert to data frame
concatenated_matrix <- as.data.frame(concatenated_matrix)
#Rename columns
colnames(concatenated_matrix) <- colnames(mean_confusion_matrix)
#Rename rows
rownames(concatenated_matrix) <- rownames(mean_confusion_matrix)
#Designate zeros with hyphens
concatenated_matrix[which(mean_confusion_matrix == 0, arr.ind = T)] <- "-"
#Add user's accuracy to data frame
concatenated_matrix <- rbind(concatenated_matrix, t(data.frame(Total = round(producers_accuracy, digits = 2))))
#Add producer's accuracy and overall accuracy to data frame
concatenated_matrix <- cbind(concatenated_matrix, data.frame(Total = round(c(users_accuracy,overall_accuracy), digits = 2)))
#Rename the total column
colnames(concatenated_matrix)[ncol(concatenated_matrix)] <- paste("Total"," (",total_number,")", sep = "")
#rownames(concatenated_matrix)[nrow(concatenated_matrix)] <- paste("Total"," (",sum(rowSums(mean_confusion_matrix)),")", sep = "")
#Rename NA cells
concatenated_matrix[which(is.na(concatenated_matrix), arr.ind = TRUE)] <- "-"
#Remove empty rows
concatenated_matrix[empty_rows,ncol(concatenated_matrix)] <- "-"
#Remove empty columns
concatenated_matrix[nrow(concatenated_matrix),empty_columns] <- "-"
#Create a table
confusion_table <- flextable(concatenated_matrix %>% rownames_to_column(" "))
#Specify the diagonal indices
diagonal_indices <- 1:nrow(concatenated_matrix)
#Add bold text to the diagonal of the table
for (i in 1:length(diagonal_indices)) {
confusion_table <- bold(confusion_table, i = diagonal_indices[i], j = diagonal_indices[i]+1, bold = TRUE, part = "body")
}
#Create a Word document
document <- read_docx()
#Add the table to a Word document
document <- document %>%
body_add_flextable(value = confusion_table)
#Save the Word document
print(document, target = paste("results/",filename,".docx", sep = ""))
#Return the table
return(confusion_table)
}
confusion.matrix(data = confusion_list, n_class = n_classes, progress = TRUE, filename = "aggregated_confusion")
#Store the number of test points for each class
test_numbers <- colSums(apply(confusion_array, c(1,2), sum, na.rm = TRUE))
confusion_array
#Convert to km2
test_numbers <- round(test_numbers / 1000000, 0)
#Store the total number of test points
total_number <- sum(test_numbers, na.rm = TRUE)
#Aggregate the confusion matrices with the mean
mean_confusion_matrix <- apply(confusion_array, c(1,2), mean, na.rm = TRUE)
#Convert to data frame and convert to columns and rows
mean_confusion_matrix <- convert.names(mean_confusion_matrix, names_classes)
#Aggregate the confusion matrices with the standard deviation
sd_confusion_matrix <- apply(confusion_array, c(1,2), sd, na.rm = TRUE)
#Convert to data frame and convert to columns and rows
sd_confusion_matrix <- convert.names(sd_confusion_matrix, names_classes)
#Aggregate the confusion matrices with the mean
sum_confusion_matrix <- apply(confusion_array, c(1,2), sum, na.rm = TRUE)
#Convert to data frame and convert to columns and rows
sum_confusion_matrix <- convert.names(sum_confusion_matrix, names_classes)
sum_confusion_matrix
#Assign the number of tested points to the name for each class
colnames(mean_confusion_matrix) <- paste(colnames(mean_confusion_matrix)," (",test_numbers,")", sep = "")
#Calculate user's accuracy
users_accuracy <- diag(as.matrix(sum_confusion_matrix))/rowSums(sum_confusion_matrix, na.rm = TRUE)
users_accuracy[is.nan(users_accuracy)] <- NA
#Store empty rows
empty_rows <- which(rowSums(mean_confusion_matrix, na.rm = TRUE) == 0)
#Calcuate producer's accuracy
producers_accuracy <- diag(as.matrix(sum_confusion_matrix))/colSums(sum_confusion_matrix, na.rm = TRUE)
producers_accuracy[is.nan(producers_accuracy)] <- NA
producers_accuracy
users_accuracy
#Store empty columns
empty_columns <- which(colSums(mean_confusion_matrix, na.rm = TRUE) == 0)
#Calculate overall Accuracy
overall_accuracy <- sum(diag(as.matrix(sum_confusion_matrix)), na.rm = TRUE)/sum(sum_confusion_matrix, na.rm = TRUE)
overall_accuracy
#Create a matrix to store concatenated matrices
concatenated_matrix <- matrix("", nrow = nrow(mean_confusion_matrix), ncol = ncol(mean_confusion_matrix))
#Convert from numeric to character and concatenate matrices cell-wise
for (i in 1:nrow(mean_confusion_matrix)) {
for (j in 1:ncol(mean_confusion_matrix)) {
concatenated_matrix[i,j] <- paste(as.character(mean_confusion_matrix[i,j]),"\u00B1", as.character(sd_confusion_matrix[i,j]), sep = "")
}
}
concatenated_matrix
#Convert to data frame
concatenated_matrix <- as.data.frame(concatenated_matrix)
#Rename columns
colnames(concatenated_matrix) <- colnames(mean_confusion_matrix)
#Rename rows
rownames(concatenated_matrix) <- rownames(mean_confusion_matrix)
concatenated_matrix
#Designate zeros with hyphens
concatenated_matrix[which(mean_confusion_matrix == 0, arr.ind = T)] <- "-"
#Add user's accuracy to data frame
concatenated_matrix <- rbind(concatenated_matrix, t(data.frame(Total = round(producers_accuracy, digits = 2))))
concatenated_matrix
producers_accuracy
sum_confusion_matrix
#Assign the number of tested points to the name for each class
colnames(sum_confusion_matrix) <- paste(colnames(sum_confusion_matrix)," (",test_numbers,")", sep = "")
#Calculate user's accuracy
users_accuracy <- diag(as.matrix(sum_confusion_matrix))/rowSums(sum_confusion_matrix, na.rm = TRUE)
users_accuracy[is.nan(users_accuracy)] <- NA
#Store empty rows
empty_rows <- which(rowSums(mean_confusion_matrix, na.rm = TRUE) == 0)
#Calcuate producer's accuracy
producers_accuracy <- diag(as.matrix(sum_confusion_matrix))/colSums(sum_confusion_matrix, na.rm = TRUE)
producers_accuracy[is.nan(producers_accuracy)] <- NA
#Store empty columns
empty_columns <- which(colSums(mean_confusion_matrix, na.rm = TRUE) == 0)
#Calculate overall Accuracy
overall_accuracy <- sum(diag(as.matrix(sum_confusion_matrix)), na.rm = TRUE)/sum(sum_confusion_matrix, na.rm = TRUE)
#Create a matrix to store concatenated matrices
concatenated_matrix <- matrix("", nrow = nrow(mean_confusion_matrix), ncol = ncol(mean_confusion_matrix))
#Convert from numeric to character and concatenate matrices cell-wise
for (i in 1:nrow(mean_confusion_matrix)) {
for (j in 1:ncol(mean_confusion_matrix)) {
concatenated_matrix[i,j] <- paste(as.character(mean_confusion_matrix[i,j]),"\u00B1", as.character(sd_confusion_matrix[i,j]), sep = "")
}
}
#Convert to data frame
concatenated_matrix <- as.data.frame(concatenated_matrix)
#Rename columns
colnames(concatenated_matrix) <- colnames(mean_confusion_matrix)
#Rename rows
rownames(concatenated_matrix) <- rownames(mean_confusion_matrix)
#Designate zeros with hyphens
concatenated_matrix[which(mean_confusion_matrix == 0, arr.ind = T)] <- "-"
#Add user's accuracy to data frame
concatenated_matrix <- rbind(concatenated_matrix, t(data.frame(Total = round(producers_accuracy, digits = 2))))
#Add producer's accuracy and overall accuracy to data frame
concatenated_matrix <- cbind(concatenated_matrix, data.frame(Total = round(c(users_accuracy,overall_accuracy), digits = 2)))
#Rename the total column
colnames(concatenated_matrix)[ncol(concatenated_matrix)] <- paste("Total"," (",total_number,")", sep = "")
#Rename NA cells
concatenated_matrix[which(is.na(concatenated_matrix), arr.ind = TRUE)] <- "-"
#Remove empty rows
concatenated_matrix[empty_rows,ncol(concatenated_matrix)] <- "-"
#Remove empty columns
concatenated_matrix[nrow(concatenated_matrix),empty_columns] <- "-"
#Create a table
confusion_table <- flextable(concatenated_matrix %>% rownames_to_column(" "))
#Specify the diagonal indices
diagonal_indices <- 1:nrow(concatenated_matrix)
#Add bold text to the diagonal of the table
for (i in 1:length(diagonal_indices)) {
confusion_table <- bold(confusion_table, i = diagonal_indices[i], j = diagonal_indices[i]+1, bold = TRUE, part = "body")
}
#Function to aggregate confusion matrices
confusion.matrix <- function(data, n_class, progress = TRUE, filename) {
#Create matrix for storing confusion matrices
confusion_matrix <- matrix()
#Create array for storing confusion matrices
confusion_array <- array(matrix(0,n_classes,n_classes), dim = c(n_classes,n_classes,length(confusion_list)))
#Aggregate confusion matrices within the hierarchical level
for (k in 1:length(confusion_list)) {
#Create template with all classes for storing confusion matrix results
confusion_template <- matrix(0,n_classes,n_classes)
#Store confusion matrix k
confusion_matrix <- confusion_list[[k]]
#Store confusion matrix from one model in the template
for (i in 1:ncol(confusion_matrix)) {
for (j in 1:nrow(confusion_matrix)) {
#Add values from confusion matrix k to the template
confusion_template[j,i] <- confusion_template[j,i] + confusion_matrix[j,i]
}
}
#Add results from confusion matrix k to the array
confusion_array[,,k] <- confusion_template
#Print progress
if (progress == T) {
print(k/length(confusion_list))
}
}
#Store the number of test points for each class
test_numbers <- colSums(apply(confusion_array, c(1,2), sum, na.rm = TRUE))
#Convert to km2
test_numbers <- round(test_numbers / 1000000, 0)
#Store the total number of test points
total_number <- sum(test_numbers, na.rm = TRUE)
#Aggregate the confusion matrices with the mean
mean_confusion_matrix <- apply(confusion_array, c(1,2), mean, na.rm = TRUE)
#Convert to data frame and convert to columns and rows
mean_confusion_matrix <- convert.names(mean_confusion_matrix, names_classes)
#Aggregate the confusion matrices with the standard deviation
sd_confusion_matrix <- apply(confusion_array, c(1,2), sd, na.rm = TRUE)
#Convert to data frame and convert to columns and rows
sd_confusion_matrix <- convert.names(sd_confusion_matrix, names_classes)
#Aggregate the confusion matrices with the mean
sum_confusion_matrix <- apply(confusion_array, c(1,2), sum, na.rm = TRUE)
#Convert to data frame and convert to columns and rows
sum_confusion_matrix <- convert.names(sum_confusion_matrix, names_classes)
#Identify rows that will be removed
#nonzero <- sort(unique(c(which(rowSums(mean_confusion_matrix, na.rm = TRUE) != 0), which(colSums(mean_confusion_matrix, na.rm = TRUE) != 0))), decreasing = F)
#Specify number of test points for all classes in the matrix
#test_numbers <- test_numbers[nonzero]
#Remove zero columns
#mean_confusion_matrix <- mean_confusion_matrix[nonzero,nonzero]
#sd_confusion_matrix <- sd_confusion_matrix[nonzero,nonzero]
#Assign the number of tested points to the name for each class
colnames(mean_confusion_matrix) <- paste(colnames(mean_confusion_matrix)," (",test_numbers,")", sep = "")
#Assign the number of tested points to the name for each class
colnames(sum_confusion_matrix) <- paste(colnames(sum_confusion_matrix)," (",test_numbers,")", sep = "")
#Calculate user's accuracy
users_accuracy <- diag(as.matrix(sum_confusion_matrix))/rowSums(sum_confusion_matrix, na.rm = TRUE)
users_accuracy[is.nan(users_accuracy)] <- NA
#Store empty rows
empty_rows <- which(rowSums(mean_confusion_matrix, na.rm = TRUE) == 0)
#Calcuate producer's accuracy
producers_accuracy <- diag(as.matrix(sum_confusion_matrix))/colSums(sum_confusion_matrix, na.rm = TRUE)
producers_accuracy[is.nan(producers_accuracy)] <- NA
#Store empty columns
empty_columns <- which(colSums(mean_confusion_matrix, na.rm = TRUE) == 0)
#Calculate overall Accuracy
overall_accuracy <- sum(diag(as.matrix(sum_confusion_matrix)), na.rm = TRUE)/sum(sum_confusion_matrix, na.rm = TRUE)
#Create a matrix to store concatenated matrices
concatenated_matrix <- matrix("", nrow = nrow(mean_confusion_matrix), ncol = ncol(mean_confusion_matrix))
#Convert from numeric to character and concatenate matrices cell-wise
for (i in 1:nrow(mean_confusion_matrix)) {
for (j in 1:ncol(mean_confusion_matrix)) {
concatenated_matrix[i,j] <- paste(as.character(mean_confusion_matrix[i,j]),"\u00B1", as.character(sd_confusion_matrix[i,j]), sep = "")
}
}
#Convert to data frame
concatenated_matrix <- as.data.frame(concatenated_matrix)
#Rename columns
colnames(concatenated_matrix) <- colnames(mean_confusion_matrix)
#Rename rows
rownames(concatenated_matrix) <- rownames(mean_confusion_matrix)
#Designate zeros with hyphens
concatenated_matrix[which(mean_confusion_matrix == 0, arr.ind = T)] <- "-"
#Add user's accuracy to data frame
concatenated_matrix <- rbind(concatenated_matrix, t(data.frame(Total = round(producers_accuracy, digits = 2))))
#Add producer's accuracy and overall accuracy to data frame
concatenated_matrix <- cbind(concatenated_matrix, data.frame(Total = round(c(users_accuracy,overall_accuracy), digits = 2)))
#Rename the total column
colnames(concatenated_matrix)[ncol(concatenated_matrix)] <- paste("Total"," (",total_number,")", sep = "")
#rownames(concatenated_matrix)[nrow(concatenated_matrix)] <- paste("Total"," (",sum(rowSums(mean_confusion_matrix)),")", sep = "")
#Rename NA cells
concatenated_matrix[which(is.na(concatenated_matrix), arr.ind = TRUE)] <- "-"
#Remove empty rows
concatenated_matrix[empty_rows,ncol(concatenated_matrix)] <- "-"
#Remove empty columns
concatenated_matrix[nrow(concatenated_matrix),empty_columns] <- "-"
#Create a table
confusion_table <- flextable(concatenated_matrix %>% rownames_to_column(" "))
#Specify the diagonal indices
diagonal_indices <- 1:nrow(concatenated_matrix)
#Add bold text to the diagonal of the table
for (i in 1:length(diagonal_indices)) {
confusion_table <- bold(confusion_table, i = diagonal_indices[i], j = diagonal_indices[i]+1, bold = TRUE, part = "body")
}
#Create a Word document
document <- read_docx()
#Add the table to a Word document
document <- document %>%
body_add_flextable(value = confusion_table)
#Save the Word document
print(document, target = paste("results/",filename,".docx", sep = ""))
#Return the table
return(confusion_table)
}
confusion.matrix(data = confusion_list, n_class = n_classes, progress = TRUE, filename = "aggregated_confusion")
confusion.matrix(data = confusion_list, n_class = n_classes, progress = TRUE, filename = "aggregated_confusion")
diag(as.matrix(sum_confusion_matrix))
sum(sum_confusion_matrix, na.rm = TRUE)
diag(as.matrix(sum_confusion_matrix)), na.rm = TRUE)
sum(diag(as.matrix(sum_confusion_matrix)), na.rm = TRUE)
diag(as.matrix(sum_confusion_matrix))
apply(confusion_array, c(1,2), function(x){mean(x)})
apply(confusion_array, c(1,2), function(x){mean(x, na.rm = TRUE)})
apply(confusion_array, c(1,2), function(x){diag(x, na.rm = TRUE)})
apply(confusion_array, c(1,2), function(x){sum(diag(x, na.rm = TRUE))/sum(x, na.rm = TRUE)})
function(x){sum(diag(x, na.rm = TRUE))/sum(x, na.rm = TRUE)}
apply(confusion_array, c(1,2), function(x){(x, na.rm = TRUE)})
apply(confusion_array, c(1,2), function(x){print(x)})
apply(confusion_array, c(1,2), function(x){diag(x)})
apply(confusion_array, c(1,2), function(x){sum(diag(x), na.rm = TRUE)/sum(x, na.rm = TRUE)})
confusion_array[,,1]
diag(confusion_array[,,1])
sum(diag(confusion_array[,,1]))/sum(confusion_array[,,1])
sum(diag(confusion_array[,,1]), na.rm = TRUE)/sum(confusion_array[,,1], na.rm = TRUE)
sum(diag(confusion_array), na.rm = TRUE)/sum(confusion_array, na.rm = TRUE)
sum(diag(confusion_array[,,1]), na.rm = TRUE)/sum(confusion_array[,,1], na.rm = TRUE)
apply(confusion_array, c(1,2), function(x){sum(diag(x), na.rm = TRUE)/sum(x, na.rm = TRUE)})
apply(confusion_array, c(3), function(x){sum(diag(x), na.rm = TRUE)/sum(x, na.rm = TRUE)})
sd(apply(confusion_array, c(3), function(x){sum(diag(x), na.rm = TRUE)/sum(x, na.rm = TRUE)}))
sd(apply(confusion_array, c(3), function(x){sum(diag(x), na.rm = TRUE)/sum(x, na.rm = TRUE)}), na.rm = TRUE)
#Import libraries
library(sf)
#Set working directory
setwd("C:/Users/adamen/OneDrive - Universitetet i Oslo/documents/Doktorgrad/Artikkel 3")
#Import spatial data
municipality_results <- st_read("results/municipality_results.gpkg")
municipality_results$proportion_land_use_mapped
municipality_results$proportion_land_use_mapped
municipality_results$proportion_land_use_mapped
median(municipality_results$proportion_land_use_mapped)
median(municipality_results$proportion_land_use_mapped, na.rm = TRUE)
municipality_results$land_use_area
municipality_results
st_centroid(municipality_results)
# Compute centroids
centroids <- st_centroid(municipality_results)
# View centroid coordinates
coords <- st_coordinates(centroids)
coords
# Combine with original attributes
centroid_data <- cbind(municipality_results$land_use_area, coords)
centroid_data
# View results
head(centroid_data)
# Combine with original attributes
centroid_data <- cbind(area = municipality_results$land_use_area, coords)
# View results
head(centroid_data)
library(spdep)
# Compute centroids
centroids <- st_centroid(municipality_results)
# View centroid coordinates
coords <- st_coordinates(centroids)
# Combine with original attributes
centroid_data <- cbind(area = municipality_results$land_use_area, coords)
# View results
head(centroid_data)
# Extract coordinates
coords <- centroid_data[, c("X", "Y")]
# Find maximum nearest neighbor distance
max_dist <- max(nbdists(knn2nb(knearneigh(coords, k = 1)), coords))
# Create neighbors within 0 to a max distance (adjust as needed, e.g., 1000)
nb <- dnearneigh(coords, 0, 1000)
# Check if all areas have neighbors
if (any(card(nb) == 0)) {
warning("Some areas have no neighbors. Increase the distance.")
}
# Create neighbors within 0 to a max distance (adjust as needed, e.g., 1000)
nb <- dnearneigh(coords, 0, 10000)
# Check if all areas have neighbors
if (any(card(nb) == 0)) {
warning("Some areas have no neighbors. Increase the distance.")
}
# Create neighbors within 0 to a max distance (adjust as needed, e.g., 1000)
nb <- dnearneigh(coords, 0, 100000)
# Check if all areas have neighbors
if (any(card(nb) == 0)) {
warning("Some areas have no neighbors. Increase the distance.")
}
# Find maximum nearest neighbor distance
max_dist <- max(nbdists(knn2nb(knearneigh(coords, k = 1)), coords))
# Get max nearest-neighbor distance
max_dist <- max(unlist(nbdists(knn2nb(knearneigh(coords, k = 1)), coords)))
max_dist
# Create neighbors within 0 to a max distance (adjust as needed, e.g., 1000)
nb <- dnearneigh(coords, 0, 70000)
# Check if all areas have neighbors
if (any(card(nb) == 0)) {
warning("Some areas have no neighbors. Increase the distance.")
}
lw <- nb2listw(nb, style = "W")  # row-standardized weights
# Replace 'your_variable' with the actual column name in your data
moran_result <- moran.test(centroid_data$your_variable, lw)
print(moran_result)
# Replace 'your_variable' with the actual column name in your data
moran_result <- moran.test(centroid_data$area, lw)
print(moran_result)
centroid_data$area
centroid_data
centroid_data$area
# Combine with original attributes
centroid_data <- as.data.frame(cbind(area = municipality_results$land_use_area, coords))
centroid_data
# View results
head(centroid_data)
# Extract coordinates
coords <- centroid_data[, c("X", "Y")]
# Get max nearest-neighbor distance
max_dist <- max(unlist(nbdists(knn2nb(knearneigh(coords, k = 1)), coords)))
# Create neighbors within 0 to a max distance (adjust as needed, e.g., 1000)
nb <- dnearneigh(coords, 0, 70000)
# Check if all areas have neighbors
if (any(card(nb) == 0)) {
warning("Some areas have no neighbors. Increase the distance.")
}
lw <- nb2listw(nb, style = "W")  # row-standardized weights
# Replace 'your_variable' with the actual column name in your data
moran_result <- moran.test(centroid_data$area, lw)
print(moran_result)
moran_perm <- moran.mc(centroid_data$area, lw, nsim = 999)
print(moran_perm)
# Set working directory to the book source
setwd("user-guide")
# Render the book
bookdown::render_book("index.Rmd", output_format = "bookdown::gitbook")
# Back to the repo root
setwd("..")
# Add all changes and commit (source + _book)
system('git add -A')
system('git commit -m "Update book"')
setwd("C:/Users/adamen/OneDrive - Universitetet i Oslo/documents/nin-qgis-plugin")
# Set working directory to the book source
setwd("user-guide")
# Render the book
bookdown::render_book("index.Rmd", output_format = "bookdown::gitbook")
# Back to the repo root
setwd("..")
# Set working directory to the book source
setwd("user-guide")
# Render the book
bookdown::render_book("index.Rmd", output_format = "bookdown::gitbook")
# Back to the repo root
setwd("..")
# Add all changes and commit (source + _book)
system('git add -A')
system('git commit -m "Update book"')
# Push latest source changes
system('git push')
# Push _book/ to gh-pages
system('git subtree push --prefix user-guide/_book origin gh-pages')
